{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f6021bc-e1d2-4385-b734-f2abdfab7b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import FloatProgress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46539aa2-1be9-4891-8c18-81d3edb8d186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 1.8.1+cu101\n",
      "cuda available: 4\n",
      "cuda current device: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"cuda available:\", torch.cuda.device_count())\n",
    "print(\"cuda current device:\", torch.cuda.current_device())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b23b2a-02a6-4ce3-bda5-1bdda6ebe099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "\n",
    "device = 2\n",
    "model_name = 'google/pegasus-xsum'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c115b278-3050-4a47-9838-9a7392a3b39d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "src_text = [\n",
    "    # \"\"\" PG&E stated it scheduled the blackouts in response to forecasts for high winds amid dry conditions. The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow.\"\"\",\n",
    "    \"\"\"(CNN)Wanted: film director, must be eager to shoot footage of golden lassos and invisible jets. CNN confirms that Michelle MacLaren is leaving the upcoming \"Wonder Woman\" movie (The Hollywood Reporter first broke the story). MacLaren was announced as director of the movie in November. CNN obtained a statement from Warner Bros. Pictures that says, \"Given creative differences, Warner Bros. and Michelle MacLaren have decided not to move forward with plans to develop and direct \\'Wonder Woman\\' together.\" (CNN and Warner Bros. Pictures are both owned by Time Warner.) The movie, starring Gal Gadot in the title role of the Amazon princess, is still set for release on June 23, 2017. It\\'s the first theatrical movie centering around the most popular female superhero. Gadot will appear beforehand in \"Batman v. Superman: Dawn of Justice,\" due out March 25, 2016. In the meantime, Warner will need to find someone new for the director\\'s chair.\"\"\"\n",
    "]\n",
    "batch = tokenizer(src_text, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e3775e-6a77-4ebf-9da2-3494647f6000",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        _model = PegasusForConditionalGeneration.from_pretrained(model_name)\n",
    "        encoder = _model.model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cf0bcee-1148-4b7d-93d9-9eda626a9173",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PegasusEncoder(\n",
       "  (embed_tokens): Embedding(96103, 1024, padding_idx=0)\n",
       "  (embed_positions): PegasusSinusoidalPositionalEmbedding(512, 1024)\n",
       "  (layers): ModuleList(\n",
       "    (0): PegasusEncoderLayer(\n",
       "      (self_attn): PegasusAttention(\n",
       "        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): PegasusEncoderLayer(\n",
       "      (self_attn): PegasusAttention(\n",
       "        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): PegasusEncoderLayer(\n",
       "      (self_attn): PegasusAttention(\n",
       "        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): PegasusEncoderLayer(\n",
       "      (self_attn): PegasusAttention(\n",
       "        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (4): PegasusEncoderLayer(\n",
       "      (self_attn): PegasusAttention(\n",
       "        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): PegasusEncoderLayer(\n",
       "      (self_attn): PegasusAttention(\n",
       "        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (6): PegasusEncoderLayer(\n",
       "      (self_attn): PegasusAttention(\n",
       "        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (7): PegasusEncoderLayer(\n",
       "      (self_attn): PegasusAttention(\n",
       "        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (8): PegasusEncoderLayer(\n",
       "      (self_attn): PegasusAttention(\n",
       "        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (9): PegasusEncoderLayer(\n",
       "      (self_attn): PegasusAttention(\n",
       "        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (10): PegasusEncoderLayer(\n",
       "      (self_attn): PegasusAttention(\n",
       "        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (11): PegasusEncoderLayer(\n",
       "      (self_attn): PegasusAttention(\n",
       "        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (12): PegasusEncoderLayer(\n",
       "      (self_attn): PegasusAttention(\n",
       "        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (13): PegasusEncoderLayer(\n",
       "      (self_attn): PegasusAttention(\n",
       "        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (14): PegasusEncoderLayer(\n",
       "      (self_attn): PegasusAttention(\n",
       "        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (15): PegasusEncoderLayer(\n",
       "      (self_attn): PegasusAttention(\n",
       "        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cf0e1ec-1ec6-448b-b39d-5c244b273954",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_layer = torch.nn.Linear(1024, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c91fe61c-7e7a-4c1a-8410-f85e6aa68208",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = torch.nn.ModuleList([model.model.encoder, additional_layer, model.model.decoder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3b095af-193e-44f4-a1fd-6cf56bf9071e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ModuleList' object has no attribute 'generate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2630/1615387167.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/shorten_sum/Expt_ShortenSum/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m    948\u001b[0m             type(self).__name__, name))\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ModuleList' object has no attribute 'generate'"
     ]
    }
   ],
   "source": [
    "my_model.generate(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5205c88d-2cff-439e-9761-f178ac02368d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,   198, 40328, 10339,   194,   148,   114,   177,  1758,   107,\n",
       "             1]], device='cuda:2')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddef9ac3-6a80-49c9-9f41-908e4f4bd287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = [1060, 110, 107, 4139, 19219, 110, 107, 110, 82214, 4137, 151, 110, 107, 87454, 2000, 14956, 108, 377, 1408, 2191, 110, 107, 1426, 110, 107, 110, 58195, 151, 110, 107, 280, 96083, 14956, 108, 377, 1408, 2191, 110, 107, 202, 323, 113, 23992, 1843, 3083, 10078, 156, 113, 4329, 131, 116, 205, 12262, 16735, 112, 25873, 169, 1601, 131, 116, 1275, 117, 4319, 112, 109, 328, 131, 116, 6879, 34108, 238, 107, 2346, 7220, 108, 13042, 108, 140, 27301, 252, 173, 109, 11716, 111, 10738, 23992, 178, 4207, 195, 2515, 135, 2859, 19031, 144, 108, 40080, 108, 244, 169, 1601, 13580, 12326, 4812, 635, 204, 109, 850, 113, 109, 30361, 8348, 233, 162, 709, 10511, 5345, 113, 5328, 111, 114, 17159, 1669, 107, 1032, 109, 49877, 19328, 138, 129, 45207, 233, 115, 114, 14996, 156, 27960, 607, 153, 1319, 238, 107, 92928, 151, 139, 64054, 116, 113, 7220, 108, 13042, 108, 122, 156, 113, 109, 11716, 111, 10738, 23992, 2515, 135, 169, 30361, 34108, 238, 113, 2859, 19031, 144, 108, 40080, 107, 139, 3843, 10078, 342, 112, 25873, 169, 1601, 131, 116, 1275, 108, 109, 898, 109, 7543, 124, 1342, 110, 107, 41184, 151, 2346, 7220, 111, 169, 1601, 108, 1843, 1560, 117, 90117, 73215, 108, 115, 8985, 488, 134, 2859, 19031, 144, 12754, 981, 110, 107, 45876, 151, 614, 587, 135, 180, 1257, 606, 130, 109, 1034, 69249, 111, 10738, 14996, 131, 115, 109, 34108, 238, 110, 107, 13580, 12326, 4812, 108, 1843, 1560, 117, 90117, 73215, 108, 16849, 142, 6838, 328, 36177, 1678, 136, 232, 173, 169, 1802, 131, 116, 561, 121, 21425, 23992, 11623, 135, 2859, 19031, 144, 107, 139, 13639, 368, 146, 2265, 169, 1601, 131, 116, 1275, 134, 109, 68521, 34108, 238, 108, 3403, 109, 7543, 124, 1342, 151, 402, 187, 209, 374, 165, 559, 109, 3083, 196, 110, 107, 547, 107, 168, 123, 116, 161, 271, 123, 116, 201, 111, 178, 123, 116, 11242, 7370, 12323, 126, 107, 2346, 7220, 131, 116, 2045, 121, 386, 121, 5505, 9859, 5677, 43921, 10436, 108, 13073, 108, 13733, 109, 664, 3843, 140, 2145, 141, 114, 1707, 121, 768, 110, 107, 1034, 362, 123, 116, 3040, 161, 1289, 122, 342, 111, 125, 272, 123, 144, 393, 13309, 112, 626, 110, 107, 189, 820, 115, 169, 1275, 107, 123, 3054, 113, 4107, 169, 1601, 131, 116, 1275, 108, 2346, 7220, 111, 169, 1750, 5459, 445, 687, 112, 109, 1275, 113, 114, 110, 107, 328, 1151, 115, 10107, 107, 343, 169, 1601, 131, 116, 177, 1750, 140, 23107, 108, 1609, 126, 140, 114, 110, 19664, 111, 109, 23992, 195, 705, 115, 1112, 107, 9859, 5677, 43921, 10436, 108, 114, 1180, 6589, 170, 1257, 109, 211, 810, 23395, 25657, 21649, 173, 265, 2826, 13580, 12326, 4812, 136, 922, 108, 243, 151, 1034, 187, 137, 8323, 119, 120, 3546, 113, 109, 23992, 120, 195, 2255, 115, 295, 115, 150, 2760, 133, 174, 185, 11326, 12323, 1577, 1034, 159, 1304, 13580, 12326, 4812, 148, 1652, 133, 174, 221, 2679, 10303, 107, 131, 2859, 19031, 144, 117, 156, 113, 109, 3617, 2724, 113, 29327, 3105, 1]\n",
    "len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4582d299-273c-4e14-b97e-49f4ee9ade45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96103"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bbed50f-7f18-4f5e-881a-f07f10c1ed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_out = model.model.encoder(**batch, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0daee6eb-3cc0-4371-97f7-6f81801d4c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 198, 1024])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_out[\"last_hidden_state\"].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c24cafd-6b75-41a0-89fb-213775a69697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 198, 1024])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_out[\"hidden_states\"][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901f5119-5e6a-4cb7-a233-d590fbcdfeb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e782e701-f721-469f-897a-eb4066f3c15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_out[\"last_hidden_state\"][0][-1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d2fc1e5-e2fd-4092-bf35-96d5cc548f4c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14887,   759,  1005,  3163,   126,  2798,   109, 25690,   116,   115,\n",
       "          1407,   112, 13378,   118,   281,  7213, 10754,  1514,  1047,   107,\n",
       "           139,  2560,   117,   112,  1329,   109,   887,   113, 39471,   107,\n",
       "         16502,  6194,  4927,   527,   195,  2798,   112,   129,  2790,   141,\n",
       "           109, 87338,   116,   162,   195,  1214,   112,   289,   224,   134,\n",
       "           583, 26568,  3469,   107,     1,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  143, 40155,   158, 77085,   151,   896,  1758,   108,   355,   129,\n",
       "          7640,   112,  3832,  6787,   113,  4347, 84464,   116,   111, 11131,\n",
       "         18585,   107, 11869, 17350,   120,  9903,  2603,  6339,  8586,   117,\n",
       "          2096,   109,  2713,   198, 40328, 10339,   194,  1397,   143,   159,\n",
       "          5090, 28942,   211,  4820,   109,   584,   250,  2603,  6339,  8586,\n",
       "           140,  1487,   130,  1758,   113,   109,  1397,   115,  1410,   107,\n",
       "         11869,  3686,   114,  1736,   135, 11235, 13339,   107,  8570,   120,\n",
       "           649,   108,   198, 12580,  1392,  3888,   108, 11235, 13339,   107,\n",
       "           111,  9903,  2603,  6339,  8586,   133,  1159,   146,   112,   696,\n",
       "           782,   122,  1017,   112,  1070,   111,  1443,  1034, 40328, 10339,\n",
       "           131,   424,   496,   143, 40155,   111, 11235, 13339,   107,  8570,\n",
       "           127,   302,  2627,   141,  2247, 11235,   107,   158,   139,  1397,\n",
       "           108, 11692, 13918,  8501, 15650,   115,   109,  1560,   868,   113,\n",
       "           109,  2107, 13515,   108,   117,   309,   323,   118,  1131,   124,\n",
       "          1185,  7801,  3039,   168,   131,   116,   109,   211, 15808,  1397,\n",
       "         57013,   279,   109,   205,   785,  2912, 16167,   107,  8501, 15650,\n",
       "           138,  1699, 14228,   115,   198, 67271,  2294,   107, 19589,   151,\n",
       "         13727,   113,  4465,   745,   640,   165,  1051,  8618,  3499,   222,\n",
       "           109,  8798,   108, 11235,   138,   217,   112,   258,   647,   177,\n",
       "           118,   109,  1758,   131,   116,  2519,   107,     1]],\n",
       "       device='cuda:2')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34a29331-0e1e-4edb-8937-3c1f9ff98b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 54, 197], device='cuda:2')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eos_indices = (batch['input_ids'] == 1).nonzero(as_tuple=True)[-1]\n",
    "eos_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f75570d-3fe9-4d00-9d23-895d84df768c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1], device='cuda:2')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = batch['input_ids'][[i for i in range(eos_indices.size()[0])],eos_indices]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fac96f6e-988f-4157-bb46-a41d7f62ccff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1,   0],\n",
       "        [113,   1]], device='cuda:2')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = batch['input_ids'].index_select(1, eos_indices)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13976973-4e5d-4214-8660-ff71958084ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eos_indices.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfa37801-2df0-4d3e-a508-e9ad4ad12b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1024])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_vecs = enc_out[\"last_hidden_state\"][[i for i in range(eos_indices.size()[0])], eos_indices, :]\n",
    "sent_vecs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c3399bf-fcd3-4175-9bf1-4857873ebe2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 198, 1024])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_out[\"last_hidden_state\"].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4128feff-a530-4e2f-b8a7-b28d7e01e0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([198])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_products = torch.mv(enc_out[\"last_hidden_state\"][0], sent_vecs[0])\n",
    "inner_products.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d69639d-b2b7-4c17-809f-a28595c85f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.6273, device='cuda:2', grad_fn=<MedianBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_products.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6777602-e9e9-4957-bcfb-e1bff2e6fb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([198])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(inner_products > inner_products.median()).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47f29380-6e87-4f9f-bac5-75d2778e848d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([99, 1024])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_out[\"last_hidden_state\"][0, (inner_products > inner_products.median()), :].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5f07999b-950a-4e06-8170-e4795747d39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[9.8643e-06, 9.8643e-06, 9.8643e-06,  ..., 9.8643e-06,\n",
       "          9.8643e-06, 9.8643e-06],\n",
       "         [9.8643e-06, 9.8643e-06, 9.8643e-06,  ..., 9.8643e-06,\n",
       "          9.8643e-06, 9.8643e-06],\n",
       "         [9.8643e-06, 9.8643e-06, 9.8643e-06,  ..., 9.8643e-06,\n",
       "          9.8643e-06, 9.8643e-06],\n",
       "         ...,\n",
       "         [9.8643e-06, 9.8643e-06, 9.8643e-06,  ..., 9.8643e-06,\n",
       "          9.8643e-06, 9.8643e-06],\n",
       "         [9.8643e-06, 9.8643e-06, 9.8643e-06,  ..., 9.8643e-06,\n",
       "          9.8643e-06, 9.8643e-06],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]]], device='cuda:2')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_out = model.model.encoder(**batch, output_hidden_states=True)\n",
    "batch_size = 2\n",
    "last_hidden_state = enc_out[\"last_hidden_state\"]\n",
    "last_hidden_state.retain_grad()\n",
    "eos_indices = (batch['input_ids'] == 1).nonzero(as_tuple=True)[-1]\n",
    "sent_vecs = last_hidden_state[[i for i in range(batch_size)], eos_indices, :]\n",
    "inner_products = torch.mv(last_hidden_state[0], sent_vecs[0])\n",
    "extracted_hidden_state = last_hidden_state[0, (inner_products > inner_products.median()), :]\n",
    "extracted_hidden_state.mean().backward()\n",
    "last_hidden_state.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "70e25287-1993-4bf4-968e-14621caa0709",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_out = model.model.encoder(**batch, output_hidden_states=True)\n",
    "batch_size = 2\n",
    "last_hidden_state = enc_out[\"last_hidden_state\"]\n",
    "last_hidden_state.retain_grad()\n",
    "eos_indices = (batch['input_ids'] == 1).nonzero(as_tuple=True)[-1]\n",
    "sent_vecs = last_hidden_state[[i for i in range(batch_size)], eos_indices, :]\n",
    "sent_vecs = sent_vecs.unsqueeze(2)\n",
    "inner_products = torch.matmul(last_hidden_state, sent_vecs)\n",
    "\n",
    "\n",
    "\n",
    "# last_hidden_state.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4597d669-bd7f-4da5-b681-8d67b944b816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c887bb3-e6b2-4f59-bc51-df52b6664495",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_vecs = sent_vecs.unsqueeze(2)\n",
    "inner_products = torch.matmul(last_hidden_state, sent_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f88ff3fe-2212-49a5-b451-0c9d205545cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 198, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_products.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e16a8621-a668-4020-9bee-75c241b26519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.median(\n",
       "values=tensor([6.7592, 2.6171], device='cuda:2', grad_fn=<MedianBackward1>),\n",
       "indices=tensor([ 6, 30], device='cuda:2'))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_products.reshape(batch_size, -1).median(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d9410342-82bf-4454-98b1-eb3de55851aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.median(\n",
       "values=tensor([5.6273, 5.6858], device='cuda:2', grad_fn=<MedianBackward1>),\n",
       "indices=tensor([12, 28], device='cuda:2'))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_products = inner_products.reshape(batch_size, -1)\n",
    "inner_products.median(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3ebf09cb-f38f-4fd3-a7dc-e7a3b54067d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "gt() received an invalid combination of arguments - got (Tensor, torch.return_types.median), but expected one of:\n * (Tensor input, Tensor other, *, Tensor out)\n * (Tensor input, Number other, *, Tensor out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13456/3231098866.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_products\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_products\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: gt() received an invalid combination of arguments - got (Tensor, torch.return_types.median), but expected one of:\n * (Tensor input, Tensor other, *, Tensor out)\n * (Tensor input, Number other, *, Tensor out)\n"
     ]
    }
   ],
   "source": [
    "torch.gt(inner_products, inner_products.median(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c152019b-363a-4734-98e2-30205c21d380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 198])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_products.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4013f422-5e18-4bc6-b074-5af13257300d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 198])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_products.median(dim=1).values.unsqueeze(1).repeat(1, 198).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "92fea8b2-d6c4-49bf-a006-076cb63c499b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 198])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(inner_products > inner_products.median(dim=1).values.unsqueeze(1)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "351d6d00-81b0-40ee-a3d8-e49be866c355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 198, 1024])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "295b72e3-21ab-49bc-94a9-499c8fb037b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True, False,  True, False,  True,  True, False, False,\n",
       "          True, False, False, False,  True,  True, False,  True,  True,  True,\n",
       "         False,  True, False, False,  True,  True,  True, False,  True,  True,\n",
       "         False,  True,  True,  True, False,  True, False,  True,  True, False,\n",
       "          True,  True,  True, False, False, False, False, False,  True, False,\n",
       "         False,  True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "         False, False,  True, False, False, False,  True, False,  True,  True,\n",
       "          True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "          True,  True, False, False, False,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
       "         False, False, False, False, False, False, False, False,  True, False,\n",
       "         False, False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         False, False, False,  True, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True, False, False,  True,  True, False,\n",
       "         False, False, False, False,  True, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False,  True,\n",
       "          True,  True, False, False, False, False,  True, False, False, False,\n",
       "          True,  True,  True, False, False, False, False,  True,  True,  True,\n",
       "          True, False, False, False,  True,  True,  True, False],\n",
       "        [ True,  True,  True, False, False,  True, False, False, False, False,\n",
       "         False, False, False, False, False, False,  True,  True, False,  True,\n",
       "         False, False, False,  True,  True, False,  True, False, False, False,\n",
       "         False, False,  True, False,  True,  True,  True,  True, False,  True,\n",
       "          True,  True,  True,  True, False,  True, False, False, False, False,\n",
       "         False, False, False,  True, False,  True,  True, False, False, False,\n",
       "         False,  True,  True, False,  True,  True,  True, False,  True, False,\n",
       "          True,  True,  True, False, False, False, False,  True,  True,  True,\n",
       "         False,  True,  True, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False,  True, False,  True,  True,\n",
       "         False, False, False, False, False, False,  True,  True,  True,  True,\n",
       "         False, False,  True, False,  True,  True,  True,  True, False,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True, False, False, False, False,  True, False,\n",
       "          True,  True,  True, False, False, False,  True, False,  True,  True,\n",
       "          True,  True,  True, False,  True, False,  True,  True,  True,  True,\n",
       "         False,  True, False,  True,  True,  True,  True, False,  True,  True,\n",
       "          True, False,  True, False,  True,  True,  True,  True,  True, False,\n",
       "         False, False, False,  True, False, False, False, False, False, False,\n",
       "         False,  True,  True, False,  True, False, False,  True]],\n",
       "       device='cuda:2')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(inner_products > inner_products.median(dim=1).values.unsqueeze(1).repeat(1, 198))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "70cd11bf-6657-49fd-a742-3be1c2c8a7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([198, 1024])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_state[, :].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cec6653-3ad1-46fe-9436-f931899f96c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
